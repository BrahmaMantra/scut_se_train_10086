# 平时作业

## 5.21课程作业 (Week 1)

![](2.png)

#### 1、请根据生成的基础数据，imsi、laccell、latitude、latitude、procedureStartTime写入HDFS用于处理离线任务。

| imsi	   | laccell	 | latitude	 | latitude	 | procedureStartTime 
|---------|----------|-----------|-----------|--------------------
| 用户imsi	 | 基站编码	    | 纬度	       | 经度	       | 进入该基站的时间           

请将您的flume.conf的配置文件内容和成功写入HDFS的截图补充填写在这里。并写一段spark代码读取写入的HDFS文件。

#### 2、请根据生成的基础数据，imsi、laccell、latitude、latitude、procedureStartTime写入Kafka用于处理实时任务。

| imsi	   | laccell	 | latitude	 | latitude	 | procedureStartTime 
|---------|----------|-----------|-----------|--------------------
| 用户imsi	 | 基站编码	    | 纬度	       | 经度	       | 进入该基站的时间           

请将您的flume.conf配置文件的内容、将数据成功写入Kafka且正常消费Kafka数据的截图补充填写在这里。同时，请提供Kafka中topic的创建以及生产者和消费者的命令。

## HBase 案例作业  (Week 2)

### 案例一、数据开发-区域人员明细汇聚

#### 准备工作

- 建表语句：
    - create_namespace('WZMF')
    - create 'WZMF:TO_MI_EVNT_NS_CELL_IMSI','crowds' 5min基站人员明细表
- 插入数据：
    - hbaseProcess代码包中的 `org\example\dataProcess\imitateDataSource.scala main` 方法提供了明细数据模拟导入

建表及执行完程序后，我们可以得知WZMF:TO_MI_EVNT_NS_CELL_IMSI表中将会存在如下基站下的人员明细数据，模拟的是2024/5/28至2024/5/29日的数据。

```
"310000_6254_140854179", 
"310000_6254_140854180", 
"310000_6254_140854181",
"310000_6234_140854182", 
"310000_6234_140854183", 
"310000_6200_140854184",
"310000_6200_140854185", 
"310000_6200_140854186"
```

#### 题目介绍

请将WZMF:TO_MI_EVNT_NS_CELL_IMSI中的数据按区域、小时汇聚到WZMF:TO_H_EVNT_NS_AREA_IMSI此表中，区域与基站关系如下：
区域1-id:"255027778846457856" 区域内的基站有：

```
"310000_6254_140854179"
"310000_6254_140854180"
"310000_6254_140854181"
```

区域2-id:"255027778846457857" 区域内的基站有：

```
"310000_6234_140854182"
"310000_6234_140854183"
```

WZMF:TO_H_EVNT_NS_AREA_IMSI表结构如下：

![](1.png)

#### 解答

请将代码包、编写代码插入到在此表WZMF:TO_H_EVNT_NS_AREA_IMSI，此表中相关的数据截图放在对应位置

1）请将scala代码包传输在此处

2）经代码运行后，查询WZMF:TO_H_EVNT_NS_AREA_IMSI的截图

### 案例二、数据开发-区域人流量汇聚统计

#### 准备工作：

建表语句：
create 'WZMF:TO_H_EVNT_NS_AREA_IMSI','crowds' 1hour区域人员明细表

#### 题目介绍

在完成案例一的程序代码后，再将WZMF:TO_H_EVNT_NS_AREA_IMSI（1hour区域人员明细表）中的2个区域（区域1-id:"255027778846457856"
、区域2-id:"255027778846457857"）按照总人数、流入人数、保持人数、流出人数的统计口径写入到WZMF:TA_H_REGION_CROWD_FLOW中。

- 1）设计WZMF:TA_H_REGION_CROWD_FLOW表结构
- 2）编写scala代码读取WZMF:
  TO_H_EVNT_NS_AREA_IMSI（1hour区域人员明细表）中的2个区域写入（总人数、流入人数、保持人数、流出人数）指标到WZMF:
  TA_H_REGION_CROWD_FLOW表中

- 相关业务口径（分析某区域，针对某一时刻B，B的上一时间跨度时刻A）：
- 流入人群：上一时刻A不在该区域，此刻B在该区域的人
- 保持人群：上一时刻A在该区域，此刻B也在该区域的人
- 流出人群：上一时刻A在该区域，此刻B在该不在该区域的人
- 当前总人数：当前时刻B的总人数

#### 解答

请将表结构设计、代码包、编写代码插入到在此表WZMF:TA_H_REGION_CROWD_FLOW，此表中相关的数据截图放在对应位置

1）设计的表结构可粘贴在此处

2）scala代码包传输在此处

3）经代码运行后，查询WZMF:TA_H_REGION_CROWD_FLOW的截图

### 案例三、后端服务开发-读取某个时间段的人流数据

1、准备工作
下载好API测试的工具，如postman

2、题目介绍
通过案例二则已经得到了WZMF:TA_H_REGION_CROWD_FLOW表中2024/5/28至2024/5/29期间2个区域的人流数据情况。

1、设计API的入参、出参（需设计成可指定某个区域的某段时间、在时间范围内每个小时的总人数、保持人数、流入人数、流出人数）
2、使用java编写出查WZMF:TA_H_REGION_CROWD_FLOW的API代码

3、解答
请将代码包及最终可以使用编写的API服务测试查数成功的截图传输在此处
1、java代码包

2、测试截图，比如postman工具测试的截图

## Flink 课程作业 (Week 3)

请结合前面课程所学知识，完成以下课题。

### 需求介绍

• 需求：统计区域用户画像。
• 分析：
数据源：基站信令数据(实时)、用户基础数据(离线)、行政区-基站关系数据(离线)。
核心业务逻辑：根据基站信令数据，统计1分钟内行政区的用户画像情况。例如：男性数量、女性数量、10-20岁人员数量、20-40人员数量、40以上人员数量。
目的地：HBase。

### 数据：

1） 基站信令数据

| imsi	   | laccell	  | latitude	 | longitude	 | procedureStartTime 
|---------|-----------|-----------|------------|--------------------
| 用户imsi	 | 当前小区的LAC	 | 所在基站纬度	   | 所在基站经度	    | 进入基站时间             

2） 用户基础数据
|imsi |gender |age
|---|---|---
|用户imsi |男1，女0 |年龄

3） 行政区-基站关系数据
该数据说明了行政区与laccell的对应关系
|region_id |laccell
|---|---
|行政区编号 |基站编号

### 作业要求

你的思路
请将您的解题思路/步骤写在这里

代码
请将您的结果代码/指令补充填写在这里

截图
请将实现的结果截图粘贴在这里

## 数据可视化（见 Doc 文档 `【第4周】20250611_大数据可视化项目实践操作` ）

